#!/usr/bin/env node

/**
 * Twitter/X Crawler CLI
 * ‰∏ìÊ≥®‰∫éÊäìÂèñTwitter/XË¥¶Âè∑‰ø°ÊÅØ‰∏éÊé®Êñá
 */

const path = require('path');
const fs = require('fs');
const { Command } = require('commander');
const scraper = require('./scrape-unified');
const fileUtils = require('./utils/fileutils');
const markdownUtils = require('./utils/markdown');
const aiExportUtils = require('./utils/ai-export');
const timeUtils = require('./utils/time');
// const mergeUtils = require('./utils/merge');

// ÂàõÂª∫ÂëΩ‰ª§Ë°åÁ®ãÂ∫è
const program = new Command();

// ÁâàÊú¨ÂíåÊèèËø∞
program
  .name('twitter-crawler')
  .description('Twitter/X Crawler - CLI tool for scraping Twitter/X content')
  .version('1.0.0');

// ÈÄöÁî®ÈÄâÈ°π
program
  .option('-d, --debug', 'Enable debug mode with verbose logs')
  .option('-o, --output <dir>', 'Output directory', './output')
  .option('-m, --merge', 'Merge all results into a single file', false)
  .option('--merge-file <filename>', 'Merge file name', 'merged')
  .option('--format <format>', 'Export format: md/json/csv', 'md');

// TwitterÂëΩ‰ª§
program
  .command('twitter')
  .description('Scrape Twitter/X account information and tweets')
  .option('-u, --username <username>', 'Twitter username (without @)')
  .option('-U, --url <profileUrl>', 'Twitter/X profile URL (e.g., https://x.com/elonmusk)')
  .option('--home', 'Scrape the home timeline (For You / Following) of the logged-in account')
  .option('--thread <tweetUrl>', 'Scrape a specific tweet thread (e.g., https://x.com/username/status/123456)')
  .option('--max-replies <number>', 'Maximum number of replies to scrape for thread mode', '100')
  .option('-f, --file <filepath>', 'File containing Twitter usernames (one per line)')
  .option('-c, --count <number>', 'Number of tweets to scrape per account', '20')
  .option('-s, --separate', 'Save each Twitter account separately', false)
  .option('--with-replies', 'Scrape with_replies tab (saved with same logic)', false)
  .option('--likes', 'Also scrape user likes (useful for persona analysis)', false)
  .option('--persona', 'Enable Persona Analysis mode (auto-generates AI prompt, includes replies)', false)
  .option('--json', 'Additionally export as JSON (consolidated into one file)', false)
  .option('--csv', 'Additionally export as CSV (consolidated into one file)', false)
  .option('--headless <boolean>', 'Run browser in headless mode', 'true')
  .option('-o, --output <dir>', 'Output directory', './output')
  .option('--timezone <timezone>', 'Timezone for timestamp output (IANA name)')
  .option('-d, --debug', 'Enable debug mode with verbose logs')
  .option('-m, --merge', 'Merge all results into a single file', false)
  .option('--merge-file <filename>', 'Merge file name', 'merged')
  .option('--format <format>', 'Export format: md/json/csv', 'md')
  .action(async (options) => {
    try {
      // È™åËØÅÂπ∂ÂàùÂßãÂåñÈÄâÈ°π
      if (!options.username && !options.url && !options.file && !options.home && !options.thread) {
        console.error('Error: Please provide Twitter username, profile URL, file, --home, or --thread');
        process.exit(1);
      }

      // Â§ÑÁêÜ Thread Ê®°ÂºèÔºà‰ºòÂÖàÂ§ÑÁêÜÔºåÂõ†‰∏∫ÂÆÉÊòØÁã¨Á´ãÁöÑÂäüËÉΩÔºâ
      if (options.thread) {
        console.log('üßµ Thread Mode ENABLED');
        const maxReplies = parseInt(options.maxReplies) || 100;

        const threadOptions = {
          tweetUrl: options.thread,
          maxReplies: maxReplies,
          outputDir: path.resolve(options.output || './output'),
          timezone: timeUtils.resolveTimezone(options.timezone || timeUtils.getDefaultTimezone()),
          saveMarkdown: true,
          exportJson: !!options.json,
          exportCsv: !!options.csv,
          generateAnalysis: true
        };

        const result = await scraper.scrapeThread(threadOptions);

        if (result.success) {
          console.log(`‚úÖ Thread scraping completed!`);
          console.log(`   - Original tweet: ${result.originalTweet ? 'Found' : 'Not found'}`);
          console.log(`   - Replies scraped: ${result.replyCount}`);
          console.log(`   - Total tweets: ${result.tweets.length}`);
          if (result.runContext?.runDir) {
            console.log(`   - Output directory: ${result.runContext.runDir}`);
          }
        } else {
          console.error(`‚ùå Thread scraping failed: ${result.error}`);
          process.exit(1);
        }

        return; // Thread Ê®°ÂºèÂÆåÊàêÂêéÁõ¥Êé•ËøîÂõû
      }

      options.count = parseInt(options.count);
      options.headless = options.headless === 'true';
      const outputDir = path.resolve(options.output || './output');
      const timezoneInput = options.timezone || timeUtils.getDefaultTimezone();
      const timezone = timeUtils.resolveTimezone(timezoneInput);

      // Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
      try {
        await fileUtils.ensureDirExists(outputDir);
      } catch (error) {
        console.error(`Failed to create output directory: ${outputDir}`, error);
        process.exit(1);
      }

      console.log('üöÄ Starting Twitter scraping task...');
      console.log(`‚è±Ô∏è Using timezone: ${timezone}`);

      // ËæÖÂä©ÂáΩÊï∞: ÂΩí‰∏ÄÂåñËæìÂÖ•‰∏∫Áî®Êà∑Âêç
      const normalizeToUsername = (input) => {
        if (!input) return null;
        const raw = String(input).trim();
        if (!raw) return null;
        // 1) Â§ÑÁêÜ @handle
        if (raw.startsWith('@')) return raw.slice(1);
        // 2) Â§ÑÁêÜ URL
        if (/^https?:\/\//i.test(raw)) {
          try {
            const u = new URL(raw);
            // ‰ªÖÊé•Âèó x.com Êàñ twitter.com
            if (!/(^|\.)x\.com$|(^|\.)twitter\.com$/i.test(u.hostname)) return null;
            // ÂèñË∑ØÂæÑÁ¨¨‰∏Ä‰∏™ÈùûÁ©∫ÊÆµ
            const seg = u.pathname.split('/').filter(Boolean)[0] || '';
            // ÊéíÈô§ÈùûÁî®Êà∑Ë∑ØÂæÑ
            const blocked = new Set(['home', 'explore', 'i', 'notifications', 'messages', 'settings', 'search']);
            if (!seg || blocked.has(seg.toLowerCase())) return null;
            return seg.replace(/^@/, '');
          } catch (_) {
            return null;
          }
        }
        // 3) ÊôÆÈÄöÁî®Êà∑Âêç
        return raw.replace(/^@/, '');
      };

      // Ê£ÄÊµãÊòØÂê¶ËØ∑Ê±Ç‰∫Ü with_replies Ê†áÁ≠æ
      const isWithReplies = (input) => {
        if (!input) return false;
        const raw = String(input).trim().toLowerCase();
        if (!raw) return false;
        if (/^https?:\/\//i.test(raw)) {
          try {
            const u = new URL(raw);
            const pathLower = u.pathname.toLowerCase();
            return pathLower.includes('/with_replies');
          } catch (_) {
            return false;
          }
        }
        return false;
      };

      // ÂàùÂßãÂåñÁî®Êà∑ÂàóË°®
      let usernames = [];
      let withReplies = !!options.withReplies;

      // Â§ÑÁêÜ Home Ê®°Âºè
      if (options.home) {
        console.log('üè† Home Timeline Mode ENABLED');
        // Êàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™ÁâπÊÆäÁöÑÂç†‰ΩçÁ¨¶Ôºåscrape-unified.js ‰ºöËØÜÂà´ÂÆÉ
        // ‰ΩÜÂÆûÈôÖ‰∏ä scrape-unified.js ÁöÑ scrapeTwitterUsers ÊòØËÆæËÆ°‰∏∫ÈÅçÂéÜÁî®Êà∑ÂêçÁöÑ
        // ÊâÄ‰ª•Êàë‰ª¨ÈúÄË¶ÅÁ®çÂæÆË∞ÉÊï¥‰∏Ä‰∏ãË∞ÉÁî®ÈÄªËæëÔºåÊàñËÄÖÊää "home" ÂΩì‰Ωú‰∏Ä‰∏™ÁâπÊÆäÁî®Êà∑Â§ÑÁêÜ

        // ËÆ©Êàë‰ª¨ÁúãÁúã scrape-unified.js ÁöÑ scrapeTwitterUsers
        // ÂÆÉÊé•Âèó‰∏Ä‰∏™Êï∞ÁªÑ„ÄÇÊàë‰ª¨ÂèØ‰ª•‰º†ÂÖ• [null] ÊàñËÄÖ ['home'] ÂêóÔºü
        // scrapeTwitterUsers ‰ºöÁî®Ëøô‰∏™ÂêçÂ≠óÂàõÂª∫ÁõÆÂΩï„ÄÇ

        // Êõ¥Â•ΩÁöÑÊñπÂºèÔºöÁõ¥Êé•Ë∞ÉÁî® scrapeXFeed ÊàñËÄÖÊûÑÈÄ†‰∏Ä‰∏™ÁâπÊÆäÁöÑ username ÂàóË°®
        // ‰ΩÜ scrapeTwitterUsers ÂÜÖÈÉ®ÊúâÂæ™ÁéØ„ÄÇ

        // ËÆ©Êàë‰ª¨‰øÆÊîπ scrape-unified.js Êù•Êõ¥Â•ΩÂú∞ÊîØÊåÅ HomeÔºåÁé∞Âú®ÂÖàÊöÇÊó∂Áî®‰∏Ä‰∏™ÁâπÊÆäÊ†áËÆ∞
        // Â¶ÇÊûúÊàë‰ª¨‰º†ÂÖ• nullÔºåscrapeTwitter ‰ºöÈªòËÆ§Âéª X_HOME_URL
        usernames.push(null);
      }

      // Persona Ê®°ÂºèËá™Âä®ÈÖçÁΩÆ
      if (options.persona) {
        console.log('üß† Persona Analysis Mode ENABLED');
        console.log('   - Auto-enabling "with_replies" to capture interactions');
        withReplies = true;

        if (options.count === 20) { // Â¶ÇÊûúÁî®Êà∑‰ΩøÁî®ÁöÑÊòØÈªòËÆ§ÂÄº (Êï∞Â≠óÊØîËæÉ)
          console.log('   - Bumping tweet count to 100 for better analysis depth');
          options.count = 100;
        }
      }

      if (options.username) {
        const u = normalizeToUsername(options.username);
        if (u) usernames.push(u);
      }
      if (options.url) {
        const u = normalizeToUsername(options.url);
        if (u) usernames.push(u);
        if (isWithReplies(options.url)) withReplies = true;
      } else if (options.file && fs.existsSync(options.file)) {
        const fileContent = fs.readFileSync(options.file, 'utf8');
        const lines = fileContent.split('\n');
        usernames = lines
          .map(line => normalizeToUsername(line))
          .filter(line => line && !String(line).startsWith('#'));
        // Â¶ÇÊûúÊñá‰ª∂Èáå‰ªª‰∏ÄË°åÂåÖÂê´ with_repliesÔºåÂàôÂêØÁî®
        if (!withReplies) {
          withReplies = lines.some(line => isWithReplies(line));
        }
      }

      if (usernames.length === 0) {
        console.error('No valid Twitter usernames/URLs');
        process.exit(1);
      }

      console.log(`Will scrape ${usernames.length} Twitter accounts, up to ${options.count} tweets per account`);

      // ËÆæÁΩÆÁà¨Ëô´ÈÄâÈ°π
      const scraperOptions = {
        outputDir,
        tweetCount: options.count,
        separateFiles: options.separate,
        headless: options.headless,
        mergeResults: options.merge,
        mergeFilename: options.mergeFile,
        exportFormat: options.format,
        withReplies,
        scrapeLikes: !!options.likes,
        exportCsv: !!options.csv,
        exportJson: !!options.json,
        timezone
      };

      // ÊâßË°åÊäìÂèñÔºàÁªü‰∏ÄÈÄªËæëÔºâ
      const results = await scraper.scrapeTwitterUsers(usernames, scraperOptions);

      // Áªü‰∏ÄÁîüÊàê AI ÂàÜÊûêÊñá‰ª∂ (Êó†ËÆ∫ÊòØÂê¶ÂºÄÂêØ persona Ê®°ÂºèÔºåÂè™Ë¶ÅÊúâÊï∞ÊçÆÂ∞±ÁîüÊàê)
      if (results && results.length > 0) {
        console.log('\nüß† Generating AI Analysis Prompts...');
        for (const result of results) {
          if (result.tweets && result.tweets.length > 0) {
            // ÂÜ≥ÂÆö‰ΩøÁî®Âì™Áßç Prompt Ê®°Êùø
            let promptType = 'persona'; // ÈªòËÆ§‰∫∫Áâ©ÁîªÂÉè
            if (!options.username && !options.url && !options.file && options.home) {
              promptType = 'feed_analysis'; // Â¶ÇÊûúÊòØ Home Ê®°ÂºèÔºåÊîπ‰∏∫‰ø°ÊÅØÊµÅÂàÜÊûê
            }

            await aiExportUtils.generatePersonaAnalysis(
              result.tweets,
              result.profile,
              result.runContext,
              promptType // ‰º†ÂÖ•Á±ªÂûã
            );
          }
        }
      }

      console.log(`‚úÖ Completed! Base output directory: ${outputDir}`);

      // ÊòæÁ§∫ÁªìÊûúÊëòË¶Å
      if (results && results.length > 0) {
        console.log('\nüìä Scraping results summary:');
        results.forEach(result => {
          const p = result.profile || {};
          const meta = [];
          if (p.displayName) meta.push(`${p.displayName}`);
          if (typeof p.followers === 'number') meta.push(`Followers: ${p.followers}`);
          if (typeof p.following === 'number') meta.push(`Following: ${p.following}`);
          console.log(`- @${result.username}: ${result.tweetCount} tweets${meta.length ? ' | ' + meta.join(' ¬∑ ') : ''}`);
        });

        const runDirs = results
          .map(result => result.runContext?.runDir)
          .filter(Boolean);
        if (runDirs.length > 0) {
          console.log('\nüìÇ Output directories:');
          runDirs.forEach(dir => console.log(`- ${dir}`));
        }
      }
    } catch (error) {
      console.error(`‚ùå Error: ${error.message}`);
      if (options.debug) {
        console.error(error);
      }
      process.exit(1);
    }
  });


// Ë∞ÉÂ∫¶Âô®ÂëΩ‰ª§
program
  .command('schedule')
  .description('Run crawler task on schedule')
  .option('-c, --config <filepath>', 'Configuration file path', './crawler-config.json')
  .option('-i, --interval <minutes>', 'Scraping interval (minutes)', '30')
  .option('--headless <boolean>', 'Run browser in headless mode', 'true')
  .option('--timezone <timezone>', 'Timezone for timestamp output (IANA name)')
  .action(async (options) => {
    try {
      // Ê£ÄÊü•ÈÖçÁΩÆÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
      if (!fs.existsSync(options.config)) {
        console.error(`Error: Config file ${options.config} does not exist`);
        process.exit(1);
      }

      options.headless = options.headless === 'true';
      const intervalMinutes = parseInt(options.interval);
      const outputDir = path.resolve(options.parent.output);

      // Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
      try {
        await fileUtils.ensureDirExists(outputDir);
      } catch (error) {
        console.error(`Failed to create output directory: ${outputDir}`, error);
        process.exit(1);
      }

      // Ë∞ÉÂ∫¶ÈÄªËæë
      console.log(`üïí Starting scheduled task, running every ${intervalMinutes} minutes`);

      // Á¨¨‰∏ÄÊ¨°Á´ãÂç≥ËøêË°å
      executeScheduledTask();

      // ËÆæÁΩÆÂÆöÊó∂Âô®
      setInterval(executeScheduledTask, intervalMinutes * 60 * 1000);

      // Ë∞ÉÂ∫¶ÊâßË°åÂáΩÊï∞
      async function executeScheduledTask() {
        try {
          const now = new Date();
          console.log(`\n[${now.toISOString()}] Executing scheduled scraping task...`);

          // Âä†ËΩΩÈÖçÁΩÆ
          const config = JSON.parse(fs.readFileSync(options.config, 'utf8'));

          const timezoneInput =
            (config.schedule && config.schedule.timezone) ||
            options.timezone ||
            timeUtils.getDefaultTimezone();
          const timezone = timeUtils.resolveTimezone(timezoneInput);
          console.log(`Timezone for this run: ${timezone}`);

          // Âü∫Êú¨ÈÄâÈ°π
          const scraperOptions = {
            outputDir,
            headless: options.headless,
            mergeResults: options.parent.merge,
            mergeFilename: `${options.parent.mergeFile}-${getFormattedDate()}`,
            exportFormat: options.parent.format,
            timezone
          };

          // ‰ªÖÊäìÂèñTwitter
          if (config.twitter && (config.twitter.usernames || config.twitter.usernameFile)) {
            let usernames = [];
            if (config.twitter.usernames && Array.isArray(config.twitter.usernames)) {
              usernames = config.twitter.usernames;
            } else if (config.twitter.usernameFile && fs.existsSync(config.twitter.usernameFile)) {
              const fileContent = fs.readFileSync(config.twitter.usernameFile, 'utf8');
              usernames = fileContent.split('\n')
                .map(line => line.trim())
                .filter(line => line && !line.startsWith('#'));
            }

            if (usernames.length > 0) {
              const twitterOptions = {
                ...scraperOptions,
                tweetCount: config.twitter.tweetCount || 20,
                separateFiles: config.twitter.separateFiles || false
              };

              await scraper.scrapeTwitterUsers(usernames, twitterOptions);
            }
          }

          console.log(`‚úÖ Scheduled task completed!`);
        } catch (schedulerError) {
          console.error(`‚ùå Scheduled task error: ${schedulerError.message}`);
          if (options.parent.debug) {
            console.error(schedulerError);
          }
          // ‰∏çÈÄÄÂá∫ËøõÁ®ãÔºåÁ≠âÂæÖ‰∏ã‰∏ÄÊ¨°Ë∞ÉÂ∫¶
        }
      }

      // ËæÖÂä©ÂáΩÊï∞ - Ëé∑ÂèñÊ†ºÂºèÂåñÊó•Êúü
      function getFormattedDate() {
        const today = new Date();
        return `${today.getFullYear()}-${String(today.getMonth() + 1).padStart(2, '0')}-${String(today.getDate()).padStart(2, '0')}`;
      }

      // ‰øùÊåÅËøõÁ®ãÊ¥ªË∑É
      console.log('Scheduler started, press Ctrl+C to exit...');
    } catch (error) {
      console.error(`‚ùå Error: ${error.message}`);
      if (options.parent.debug) {
        console.error(error);
      }
      process.exit(1);
    }
  });

// ‰æãÂ≠êÂëΩ‰ª§
program
  .command('examples')
  .description('Show usage examples')
  .action(() => {
    console.log(`
Twitter/X Crawler Usage Examples:

Scrape a single Twitter account (username):
  $ node cli.js twitter -u elonmusk -c 50 -o ./output

Scrape a single Twitter account (profile URL):
  $ node cli.js twitter -U https://x.com/elonmusk -c 50 -o ./output

Scrape multiple Twitter accounts from file (can mix usernames/@handles/profile URLs):
  $ node cli.js twitter -f twitter_accounts.txt -c 20 -o ./output --merge

Scheduled scraping:
  $ node cli.js schedule -c ./crawler-config.json -i 60 -o ./output

Example config file (crawler-config.json):
{
  "twitter": {
    "usernames": ["elonmusk", "BillGates"],
    "tweetCount": 50,
    "separateFiles": true,
    "useAxios": false
  }
}
`);
  });

// Áõ¥Êé•ËøêË°å
if (require.main === module) {
  program
    .command('monitor')
    .description('Monitor multiple users for new tweets and generate a daily report')
    .requiredOption('-u, --users <users>', 'Comma-separated list of usernames (e.g. elonmusk,trump)')
    .action(async (options) => {
      try {
        const { ScraperEngine } = require('./core/scraper-engine');
        const { MonitorService } = require('./core/monitor-service');

        const engine = new ScraperEngine();
        await engine.init();
        const success = await engine.loadCookies();
        if (!success) {
          console.error('Failed to load cookies. Exiting.');
          process.exit(1);
        }

        const monitor = new MonitorService(engine);
        const usernames = options.users.split(',').map(u => u.trim());

        await monitor.runMonitor(usernames);

        await engine.close();
        process.exit(0);
      } catch (error) {
        console.error('Monitor failed:', error);
        process.exit(1);
      }
    });

  program.parse(process.argv);
}

module.exports = program; 
