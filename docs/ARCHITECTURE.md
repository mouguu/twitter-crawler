# Technical Architecture

Deep dive into XRCrawler's technical architecture and design decisions.

## Overview

XRCrawler implements enterprise-grade features for reliability and stealth, built entirely in TypeScript.

## Core Components

### Scraping Engine

**Location**: `core/scraper-engine.ts`

The main orchestrator that coordinates all scraping activities:

- Mode selection (GraphQL API, Puppeteer DOM, Mixed)
- Strategy switching based on limits
- Error handling and retry logic
- Progress tracking and checkpointing

### Timeline Runners

**GraphQL API Runner** (`core/timeline-api-runner.ts`):

- Fast, lightweight scraping using Twitter's internal GraphQL API
- No browser needed
- Limited to ~800 tweets (server-side restriction)

**Puppeteer DOM Runner** (`core/timeline-dom-runner.ts`):

- Full browser automation for deeper timeline access
- Handles complex scenarios and error recovery
- Virtually unlimited depth

**Date Chunker** (`core/timeline-date-chunker.ts`):

- Implements reverse-chronological date chunking
- Splits timeframes into monthly chunks
- Uses search queries (`from:user since:A until:B`) instead of scrolling

### Deep Search & Date Chunking

To bypass the ~800 tweet limit, XRCrawler uses intelligent date chunking:

1. **Intelligent Segmentation**: Timeframe split into monthly chunks (e.g., 2025-11, 2025-10, 2025-09...)
2. **Search-Based Retrieval**: Uses Puppeteer to perform advanced search queries instead of scrolling
3. **Smart Pacing**: Limits scrolling per chunk to prevent frontend crashes
4. **Auto-Stop**: Automatically stops once target count is reached

### Session Management

**Session Manager** (`core/session-manager.ts`):

- Loads all cookie files from `cookies/` directory
- Automatic rotation on rate limits
- Chunk retry mechanism (prevents data gaps)

**Cookie Manager** (`core/cookie-manager.ts`):

- Cookie file loading and validation
- Session validation before use

**Key Features**:

- **Multi-Account Support**: Multiple cookie files
- **Automatic Rotation**: Switches sessions on 429 errors or load failures
- **Chunk Retry**: If session fails during a chunk, next session retries the same chunk
- **Configurable**: Enable/disable rotation via `enableRotation` option

### Browser Management

**Browser Manager** (`core/browser-manager.ts`):

- Creates and manages browser instances
- Handles browser lifecycle

**Browser Pool** (`core/browser-pool.ts`):

- Reuses browser instances to reduce overhead
- Improves performance for multiple scrapes

**Fingerprint Manager** (`core/fingerprint-manager.ts`):

- Injects realistic browser fingerprints using `fingerprint-injector`
- Canvas & WebGL noise randomization
- Hardware emulation matching User-Agent

### Rate Limiting & Error Handling

**Rate Limit Manager** (`core/rate-limit-manager.ts`):

- Detects 429 errors and rate limit responses
- Triggers session rotation
- Configurable retry delays

**Error Snapshotter** (`core/error-snapshotter.ts`):

- Captures screenshots on errors
- Saves error details for debugging

**Error Classifier** (`utils/error-classifier.ts`):

- Classifies errors into categories
- Provides user-friendly error messages

### Progress Management

**Progress Manager** (`core/progress-manager.ts`):

- Tracks scraping progress
- Saves checkpoints (oldest tweet ID)
- Enables resume functionality

### Performance Monitoring

**Metrics Collector** (`core/metrics-collector.ts`):

- Collects real-time performance metrics
- Scraping speed, success rates, resource usage

**Performance Monitor** (`core/performance-monitor.ts`):

- Real-time performance tracking
- Resource usage monitoring

### Request Queue

**Task Queue** (`server/task-queue.ts`):

- Manages concurrent requests
- Priority-based queuing
- Prevents conflicts and ensures orderly execution

## Hybrid Architecture

### Frontend (React + Vite)

**Location**: `frontend/`

- Modern, responsive UI
- Real-time updates via Server-Sent Events (SSE)
- Component-based architecture:
  - `HeaderBar`: API key and navigation
  - `TaskForm`: Task creation
  - `Mission Control` cards: Live queue status, logs, and download
  - `SessionManager`: Cookie file management
  - `ErrorNotification`: Error display

### Backend (Node.js + Express)

**Location**: `server.ts`, `server/`

- Orchestrates scraping process
- Manages Request Queue and Session Rotation
- Handles Twitter scraping via TypeScript/Puppeteer
- REST API endpoints for frontend
- SSE streaming for real-time updates

### Platform Adapters

**Location**: `core/platforms/`

- Modular adapter system for multi-platform support
- `twitter-adapter.ts`: Twitter/X scraping
- `reddit-adapter.ts`: Reddit scraping via HTTP API
- Registry pattern for easy platform addition

## Directory Structure

```
XRCrawler/
â”œâ”€â”€ cmd/                   # Entry points
â”‚   â”œâ”€â”€ cli.ts            # CLI application
â”‚   â”œâ”€â”€ start-server.ts   # API server
â”‚   â””â”€â”€ start-worker.ts   # Queue worker
â”œâ”€â”€ core/                  # Core business logic
â”‚   â”œâ”€â”€ scrape-unified.ts # Main scraping API
â”‚   â”œâ”€â”€ platforms/        # Platform adapters
â”‚   â”‚   â”œâ”€â”€ twitter-adapter.ts
â”‚   â”‚   â”œâ”€â”€ reddit-adapter.ts
â”‚   â”‚   â””â”€â”€ registry.ts
â”‚   â”œâ”€â”€ queue/            # BullMQ workers
â”‚   â”œâ”€â”€ db/               # Prisma repositories
â”‚   â””â”€â”€ ...               # Scraping modules
â”œâ”€â”€ frontend/             # React + Vite UI
â”‚   â””â”€â”€ src/components/   # shadcn/ui components
â”œâ”€â”€ wasm/                 # Rust/WASM modules
â”‚   â”œâ”€â”€ tweet-cleaner/
â”‚   â”œâ”€â”€ reddit-cleaner/
â”‚   â””â”€â”€ url-normalizer/
â”œâ”€â”€ cookies/              # Session storage
â”œâ”€â”€ output/               # Scraped data
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ config/               # Configuration
```

## Security Features

### API Key Protection

- Optional API key authentication for all `/api/*` endpoints
- Set via `API_KEY` environment variable
- Frontend sends key via `X-API-Key` header or `api_key` query parameter

### Path Validation

- All file download paths validated to prevent directory traversal
- Output path manager with security checks

### Session Validation

- Cookie files validated before use
- Prevents invalid sessions from causing errors

## Scraping Modes

### GraphQL API Mode (Default)

- **Speed**: âš¡ Fast
- **Limitation**: âš ï¸ ~800 tweet limit
- **Best For**: Quick monitoring, daily updates, small profiles

### Puppeteer DOM Mode

- **Speed**: ğŸ¢ Slower (full browser rendering)
- **Limitation**: âœ… Virtually unlimited
- **Best For**: Archival, large datasets, historical analysis

### Mixed Mode

- **Speed**: âš¡ Fast start, ğŸ¢ Slower continuation
- **Logic**: Starts with GraphQL API, switches to Puppeteer when limit reached
- **Best For**: Large profiles needing both speed and depth

## Data Flow

1. **User Request** â†’ Frontend/CLI
2. **Task Creation** â†’ Task Queue
3. **Session Selection** â†’ Session Manager
4. **Mode Selection** â†’ Scraper Engine
5. **Scraping Execution** â†’ Timeline Runner (API or DOM)
6. **Progress Updates** â†’ Progress Manager â†’ SSE/Frontend
7. **Error Handling** â†’ Error Snapshotter â†’ Error Classification
8. **Result Export** â†’ Output Manager â†’ File System

## Recent Improvements

- HTTP-based Reddit bridge (replaced stdout parsing)
- Modular UI components (split from monolithic App.tsx)
- Request queue orchestration (moved to `server/task-queue.ts`)
- Performance monitoring with real-time metrics
- Error snapshotting for debugging
- Browser pool for performance
- Progress management with checkpointing
- Mixed mode automatic switching
- Enhanced error handling and classification
