#!/usr/bin/env node
/**
 * Markdownæ–‡ä»¶åˆå¹¶å·¥å…·æ¨¡å—
 * åˆå¹¶æŒ‡å®šç›®å½•çš„mdæ–‡ä»¶ï¼Œæ·»åŠ ç´¢å¼•ï¼Œå¹¶å¯é€‰æ‹©åˆ é™¤æºæ–‡ä»¶
 */

const fs = require('fs').promises;
const path = require('path');
const fileUtils = require('./fileutils');

const DEFAULT_CONVERGENCE_DIR = path.join(fileUtils.DEFAULT_OUTPUT_ROOT, 'convergence');

// è·å– Cookie æ–‡ä»¶è·¯å¾„ï¼ˆä¹Ÿç”¨äºè¯»å–ç”¨æˆ·åï¼‰
const COOKIE_FILE = path.join(__dirname, '..', 'env.json');

/**
 * å°è¯•ä» env.json è¯»å–ç”¨æˆ·å
 * @returns {Promise<string|null>} ç”¨æˆ·åæˆ– null
 */
async function getUsernameFromEnv() {
  try {
    const envContent = await fs.readFile(COOKIE_FILE, 'utf-8');
    const envData = JSON.parse(envContent);
    // å‡è®¾ env.json ç»“æ„æ˜¯ { "cookies": [...], "username": "YourUsername" }
    // æˆ–è€…ç›´æ¥æ˜¯ { "username": "YourUsername", ...å…¶ä»–cookieä¿¡æ¯ }
    if (typeof envData.username === 'string') {
      return envData.username;
    }
    // å…¼å®¹æ—§æ ¼å¼æˆ–ä»…åŒ…å« cookie çš„æ•°ç»„æ ¼å¼
    if (Array.isArray(envData)) {
        // å°è¯•ä» cookie ä¸­æ‰¾ 'username' (ä¸å¤ªå¯é ï¼Œä½†å¯ä»¥è¯•è¯•)
        const usernameCookie = envData.find(c => c.name === 'username');
        if (usernameCookie) {
             return usernameCookie.value;
        }
    }
    console.warn("'username' field not found in env.json.");
    return null;
  } catch (error) {
    if (error.code !== 'ENOENT') { // æ–‡ä»¶ä¸å­˜åœ¨æ˜¯æ­£å¸¸æƒ…å†µ
      console.warn(`Failed to read env.json to get username: ${error.message}`);
    }
    return null;
  }
}

/**
 * åˆå¹¶æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ .md æ–‡ä»¶ (æ’é™¤ç‰¹å®šå‰ç¼€çš„æ–‡ä»¶)
 * @param {string} sourceDir è¦åˆå¹¶æ–‡ä»¶çš„æºç›®å½•.
 * @param {string} outputDir åˆå¹¶åæ–‡ä»¶çš„è¾“å‡ºç›®å½•.
 * @param {string} platform å¹³å°æ ‡è¯† ('x' or 'medium') ç”¨äºç”Ÿæˆæ–‡ä»¶åå’Œå…ƒæ•°æ®.
 * @param {boolean} deleteSourceFiles æ˜¯å¦åˆ é™¤æºæ–‡ä»¶ï¼Œé»˜è®¤ä¸º false.
 * @returns {Promise<string|null>} åˆå¹¶åçš„æ–‡ä»¶è·¯å¾„ï¼Œæˆ– null.
 */
async function mergeMarkdownFiles(sourceDir, outputDir, platform, deleteSourceFiles = false) {
  // Validate required parameters
  if (!sourceDir || !outputDir || !platform) {
      console.error('mergeMarkdownFiles missing required parameters: sourceDir, outputDir, platform');
      return null;
  }

  try {
    console.log(`[${platform.toUpperCase()}] Starting to merge Markdown files from ${sourceDir}...`);
    await fileUtils.ensureBaseStructure(); // Ensures base dirs exist
    await fs.mkdir(outputDir, { recursive: true }); // Ensure specific output dir exists
    
    // è·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„Markdownæ–‡ä»¶
    const mdFiles = await fileUtils.getMarkdownFiles(sourceDir); // Pass sourceDir
    
    if (mdFiles.length === 0) {
      console.log(`[${platform.toUpperCase()}] No Markdown files found to merge in ${sourceDir}`);
      return null;
    }

    // æŒ‰æ–‡ä»¶åæ’åºï¼Œæ–°çš„åœ¨å‰
    mdFiles.sort((a, b) => path.basename(b).localeCompare(path.basename(a)));

    console.log(`[${platform.toUpperCase()}] Found ${mdFiles.length} Markdown files ready to merge`);
    
    // -- å¼€å§‹æ„å»ºå…ƒæ•°æ® --
    const mergeTime = new Date();
    const username = await getUsernameFromEnv(); // Username might be specific to platform if needed
    const dateString = mergeTime.toISOString().split('T')[0];
    const timeString = mergeTime.toTimeString().split(' ')[0].replace(/:/g, '');
    const mergedFilename = `merged-${platform}-${dateString}-${timeString}.md`; // Include platform

    let metadataBlock = [
      '---',
      `platform: ${platform}`,
      `mergedFilename: ${mergedFilename}`,
      `mergeTimestamp: ${mergeTime.toISOString()}`,
      // Use platform-specific username if available, otherwise generic
      username ? `accountUsername: ${username}` : '# accountUsername: (not found in env.json/medium-cookies.json)',
      `totalItemsMerged: ${mdFiles.length}`,
      '---',
      '\n' 
    ].join('\n');
    // -- å…ƒæ•°æ®æ„å»ºç»“æŸ --

    // è¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹å¹¶æ·»åŠ ç´¢å¼•åæ‹¼æ¥
    let allItemsContent = ''; // Renamed variable
    const separator = '\n\n---\n\n'; 
    let itemIndex = 1; // Renamed variable
    
    for (const file of mdFiles) {
      const content = await fs.readFile(file, 'utf-8');
      // Add index before the content of each file
      allItemsContent += `## ${itemIndex}.\n\n${content}${separator}`;
      itemIndex++; 
    }
    
    // æ¸…ç†æœ«å°¾å¤šä½™çš„åˆ†éš”ç¬¦
    if (allItemsContent.endsWith(separator)) {
        allItemsContent = allItemsContent.slice(0, -separator.length);
    }

    // åˆå¹¶å…ƒæ•°æ®å’Œå†…å®¹
    const finalContent = metadataBlock + allItemsContent;

    // ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    const mergedFilePath = path.join(outputDir, mergedFilename);
    await fs.writeFile(mergedFilePath, finalContent, 'utf-8');
    console.log(`[${platform.toUpperCase()}] âœ… All Markdown files merged and saved as: ${mergedFilename}`);

    // å¦‚æœéœ€è¦ï¼Œåˆ é™¤æºæ–‡ä»¶
    if (deleteSourceFiles) {
      console.log(`[${platform.toUpperCase()}] Deleting ${mdFiles.length} source Markdown files from ${sourceDir}...`);
      let deletedCount = 0;
      for (const file of mdFiles) {
        // Safety check (redundant due to initial filter but safe)
        if (path.basename(file).startsWith('merged-') || path.basename(file).startsWith('digest-')) {
            console.warn(`[${platform.toUpperCase()}] Skipping deletion of protected file: ${file}`);
            continue;
        }
        try {
          await fs.unlink(file);
          deletedCount++;
        } catch (delError) {
          console.warn(`[${platform.toUpperCase()}] Failed to delete file: ${file}`, delError.message);
        }
      }
      console.log(`[${platform.toUpperCase()}] Successfully deleted ${deletedCount} source files`);
    }

    return mergedFilePath;
  } catch (error) {
    console.error(`[${platform.toUpperCase()}] Failed to merge Markdown files:`, error.message);
    return null;
  }
}

/**
 * Formats a single tweet object into a Markdown string for convergence.
 * (Adapts logic from markdownUtils.saveTweetAsMarkdown)
 * @param {Object} tweet Tweet object.
 * @param {number} index Index for the item.
 * @returns {string} Markdown formatted string.
 */
function formatTweetForConvergence(tweet, index) {
  const date = new Date(tweet.time);
  const content = [
    `## ${index}. (X) ${date.toLocaleDateString()} ${date.toLocaleTimeString()}`, // Add platform hint
    '',
    `> ${tweet.text.replace(/\n/g, '\n> ')}`, // Basic blockquote
    '',
    `â¤ï¸ ${tweet.likes || 0} | ğŸ”„ ${tweet.retweets || 0} | ğŸ’¬ ${tweet.replies || 0}${tweet.hasMedia ? ' | ğŸ–¼ï¸' : ''}`,
    `ğŸ”— [View on X](${tweet.url})`,
  ].join('\n');
  return content;
}

/**
 * Formats a single Medium article object into a Markdown string for convergence.
 * (Adapts logic from markdownUtils.saveMediumArticleAsMarkdown)
 * @param {Object} article Article object.
 * @param {number} index Index for the item.
 * @returns {string} Markdown formatted string.
 */
function formatMediumForConvergence(article, index) {
  const publishedDate = article.publishedDate ? new Date(article.publishedDate) : null;
  const title = article.title || 'Untitled';
  const content = [
    `## ${index}. (Medium) ${title}`, // Add platform hint and Title
    '',
    article.authorName ? `*By ${article.authorName}*` : '',
    publishedDate ? `*Published on ${publishedDate.toLocaleDateString()}*` : '',
    '',
    '---',
    '',
    article.content, // Assumes content is already Markdown
    '',
    '---',
    `ğŸ”— [View Original](${article.originalUrl || article.url})`, // Prefer original URL if via Freedium
    (article.originalUrl && article.url !== article.originalUrl) ? `ğŸ”— [View Scraped Version](${article.url})` : ''
  ].filter(Boolean).join('\n');
  return content;
}

/**
 * Merges scraped items from multiple platforms into a single convergence file.
 * @param {Array<Object>} twitterResults Array of tweet objects from scrape.
 * @param {Array<Object>} mediumResults Array of article objects from scrapeMediumArticle.
 * @param {string} [outputDir] Output directory, defaults to CONVERGENCE_DIR.
 * @returns {Promise<string|null>} Path to the convergence file or null.
 */
async function mergeAllPlatforms(twitterResults = [], mediumResults = [], outputDir = DEFAULT_CONVERGENCE_DIR) {
  const allItems = [
      ...twitterResults.map(item => ({ ...item, platform: 'x' })),
      ...mediumResults.map(item => ({ ...item, platform: 'medium' }))
  ];

  if (allItems.length === 0) {
    console.log('[Convergence] No content found from any platform to merge.');
    return null;
  }

  // Sort all items by date (time for tweets, publishedDate or scrape time for articles)
  allItems.sort((a, b) => {
      const dateA = new Date(a.time || a.publishedDate || Date.now()); // Fallback needed
      const dateB = new Date(b.time || b.publishedDate || Date.now());
      return dateB - dateA; // Sort descending (newest first)
  });

  console.log(`[Convergence] Starting to merge ${allItems.length} items (from ${twitterResults.length} X, ${mediumResults.length} Medium)...`);
  await fileUtils.ensureBaseStructure(); // Ensure base dirs exist
  await fs.mkdir(outputDir, { recursive: true }); // Ensure convergence dir exists

  // --- Build Metadata --- 
  const mergeTime = new Date();
  const username = await getUsernameFromEnv(); // Assuming one primary username for now
  const dateString = mergeTime.toISOString().split('T')[0];
  const timeString = mergeTime.toTimeString().split(' ')[0].replace(/:/g, '');
  const mergedFilename = `convergence-${dateString}-${timeString}.md`;

  const metadataBlock = [
    '---',
    `mergedFilename: ${mergedFilename}`,
    `mergeTimestamp: ${mergeTime.toISOString()}`,
    username ? `primaryAccount: ${username}` : '# primaryAccount: (not found in env.json)',
    `totalItemsMerged: ${allItems.length}`,
    `twitterItems: ${twitterResults.length}`,
    `mediumItems: ${mediumResults.length}`,
    '---',
    '\n'
  ].join('\n');
  // --- Metadata End --- 

  let finalContent = metadataBlock;
  const separator = '\n\n---\n\n';
  let itemIndex = 1;

  for (const item of allItems) {
    let formattedItem = '';
    if (item.platform === 'x') {
        formattedItem = formatTweetForConvergence(item, itemIndex);
    } else if (item.platform === 'medium') {
        formattedItem = formatMediumForConvergence(item, itemIndex);
    }
    
    if (formattedItem) {
        finalContent += formattedItem + separator;
        itemIndex++;
    }
  }

  // Clean trailing separator
  if (finalContent.endsWith(separator)) {
    finalContent = finalContent.slice(0, -separator.length);
  }

  // Save the convergence file
  const mergedFilePath = path.join(outputDir, mergedFilename);
  try {
    await fs.writeFile(mergedFilePath, finalContent, 'utf-8');
    console.log(`[Convergence] âœ… Convergence file saved successfully: ${mergedFilename}`);
    return mergedFilePath;
  } catch (error) {
      console.error(`[Convergence] Failed to save convergence file:`, error.message);
      return null;
  }
}

// Export the new function along with the old one
module.exports = { mergeMarkdownFiles, mergeAllPlatforms }; 
