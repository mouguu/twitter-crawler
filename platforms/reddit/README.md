# UofT Reddit Data System ğŸ¯

A comprehensive, unified system for scraping, standardizing, and analyzing University of Toronto Reddit data. This system addresses the complex challenges of Reddit's nested data structure and provides high-quality, research-ready datasets.

## ğŸŒŸ Key Features

### ğŸ”„ **Unified Data Pipeline**

- **Scraping**: Multi-strategy Reddit data collection
- **Standardization**: Automated content cleaning and normalization
- **Export**: High-quality CSV datasets with comprehensive metadata
- **Analysis**: Built-in data quality assessment

### ğŸ§  **Advanced Data Processing**

- **Comment Tree Flattening**: Converts Reddit's nested structure to analyzable format
- **Content Normalization**: Handles emojis, links, mentions, deleted content
- **Quality Scoring**: Automated assessment for dataset curation
- **Metadata Preservation**: Maintains original data alongside cleaned versions

### ğŸ¯ **Research-Ready Output**

- **Standardized CSV Format**: Compatible with Excel, Python, R, etc.
- **Quality Metrics**: Built-in quality scores for each post and comment
- **Comprehensive Metadata**: Author info, timestamps, engagement metrics
- **Flexible Filtering**: Export by quality level, content type, etc.

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. å¯åŠ¨ç³»ç»Ÿ

```bash
python3 reddit_system.py
```

### 3. ä½¿ç”¨äº¤äº’èœå•

ç³»ç»Ÿæä¾›ç›´è§‚çš„äº¤äº’ç•Œé¢ï¼š

```text
ğŸš€ UofT Reddit System
==================================================
ğŸ“Š University of Toronto Reddit Data System
ğŸ¯ Professional dataset creation and analysis
==================================================

Available Actions:
1. ğŸ”„ Scrape new posts
2. ğŸ“Š Export professional CSV (Kaggle-ready)
3. ğŸ“‹ Export standardized data (legacy)
4. ğŸ” Analyze data quality
5. ğŸ“Š Show system status
6. âŒ Exit
```

## æ–‡ä»¶è¯´æ˜

### å•ä¸ªå¸–å­æ–‡ä»¶ç»“æ„

æ¯ä¸ªå¸–å­JSONæ–‡ä»¶åŒ…å«ï¼š

```json
{
  "id": "å¸–å­ID",
  "title": "å¸–å­æ ‡é¢˜",
  "author": "ä½œè€…ç”¨æˆ·å",
  "score": è¯„åˆ†æ•°,
  "selftext": "å¸–å­æ­£æ–‡å†…å®¹",
  "url": "å¸–å­é“¾æ¥",
  "created_utc": åˆ›å»ºæ—¶é—´æˆ³,
  "num_comments": è¯„è®ºæ€»æ•°,
  "comments": [
    {
      "id": "è¯„è®ºID",
      "author": "è¯„è®ºä½œè€…",
      "body": "è¯„è®ºå†…å®¹",
      "score": è¯„è®ºè¯„åˆ†,
      "replies": [åµŒå¥—å›å¤...]
    }
  ]
}
```

### ç»Ÿè®¡æŠ¥å‘Š (00_REPORT_statistics.json)

åŒ…å«ï¼š

- åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ€»å¸–å­æ•°ã€æ€»è¯„è®ºæ•°ã€å¹³å‡è¯„åˆ†ï¼‰
- æŒ‰è¯„åˆ†æ’åºçš„çƒ­é—¨å¸–å­ Top 5
- æŒ‰è¯„è®ºæ•°æ’åºçš„çƒ­é—¨å¸–å­ Top 5

## æŠ€æœ¯åŸç†

ä½¿ç”¨Redditçš„ `.json` APIæ¥å£ï¼š

- è·å–å¸–å­åˆ—è¡¨: `https://www.reddit.com/r/UofT/hot.json`
- è·å–å¸–å­è¯¦æƒ…: `https://www.reddit.com/r/UofT/comments/[post_id]/[title].json`

è¿™ç§æ–¹æ³•ï¼š

- âœ… ç®€å•ç¨³å®šï¼Œæ— éœ€æ¨¡æ‹Ÿæµè§ˆå™¨
- âœ… è·å–å®Œæ•´æ•°æ®ï¼ŒåŒ…æ‹¬æ‰€æœ‰è¯„è®ºå’Œå›å¤
- âœ… æ— éœ€ç™»å½•æˆ–APIå¯†é’¥
- âœ… é¿å¼€å¤æ‚çš„å‰ç«¯æ¸²æŸ“å’Œåçˆ¬æœºåˆ¶

## æ³¨æ„äº‹é¡¹

1. **è¯·æ±‚é¢‘ç‡**: å†…ç½®1ç§’å»¶è¿Ÿï¼Œè¯·å‹¿ä¿®æ”¹ä¸ºæ›´é«˜é¢‘ç‡
2. **æ•°æ®æ—¶æ•ˆ**: æŠ“å–çš„æ˜¯å½“å‰æ—¶åˆ»çš„æ•°æ®å¿«ç…§
3. **å­˜å‚¨ç©ºé—´**: 50ä¸ªå¸–å­çº¦å ç”¨å‡ MBç©ºé—´
4. **ç½‘ç»œç¯å¢ƒ**: éœ€è¦èƒ½æ­£å¸¸è®¿é—®Reddit

## è‡ªå®šä¹‰ä¿®æ”¹

å¦‚éœ€ä¿®æ”¹æŠ“å–æ•°é‡æˆ–å…¶ä»–å‚æ•°ï¼Œå¯ç¼–è¾‘ `uoft_scraper.py` ä¸­çš„ç›¸å…³è®¾ç½®ï¼š

```python
# ä¿®æ”¹æŠ“å–æ•°é‡ï¼ˆç¬¬155è¡Œé™„è¿‘ï¼‰
post_urls = self.get_uoft_posts(50)  # æ”¹ä¸ºå…¶ä»–æ•°å­—

# ä¿®æ”¹è¯·æ±‚å»¶è¿Ÿï¼ˆç¬¬21è¡Œï¼‰
self.delay = 1.0  # æ”¹ä¸ºå…¶ä»–ç§’æ•°
```

## æ•°æ®åˆ†æ

å¯ä»¥ä½¿ç”¨ `analyze_data.py` å¯¹æŠ“å–çš„æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥åˆ†æï¼š

```bash
python3 analyze_data.py
```

## è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œè¯·éµå®ˆRedditçš„ä½¿ç”¨æ¡æ¬¾å’Œrobots.txtè§„åˆ™ã€‚
