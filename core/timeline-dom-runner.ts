import * as constants from '../config/constants';
import type { ProfileInfo, Tweet } from '../types/tweet-definitions';
import * as fileUtils from '../utils';
import * as markdownUtils from '../utils';
import * as exportUtils from '../utils';
import * as screenshotUtils from '../utils';
import { cleanTweetsFast, sleepOrCancel, waitOrCancel } from '../utils';
import * as dataExtractor from './data-extractor';
import { ScraperErrors } from './errors';
import type { ScraperEngine } from './scraper-engine';
import type { ScrapeTimelineConfig, ScrapeTimelineResult } from './scraper-engine.types';

export async function runTimelineDom(
  engine: ScraperEngine,
  config: ScrapeTimelineConfig,
): Promise<ScrapeTimelineResult> {
  // ç¡®ä¿é¡µé¢å¯ç”¨
  if (!engine.getPageInstance()) {
    await engine.ensurePage();
  }

  // Start performance monitoring
  engine.performanceMonitor.reset();
  engine.performanceMonitor.setMode('puppeteer');
  engine.performanceMonitor.start();
  engine.emitPerformanceUpdate(true);

  const {
    username,
    limit = 50,
    mode = 'timeline',
    searchQuery,
    saveMarkdown = true,
    saveScreenshots = false,
    exportCsv = false,
    exportJson = false,
    progressBase = 0,
  } = config as any;
  const progressTarget = (config as any).progressTarget; // Temporary cast if type is strict
  let { runContext } = config;
  const totalTarget = progressTarget ?? progressBase + limit;

  // Initialize runContext if missing
  if (!runContext) {
    const identifier = username || searchQuery || 'unknown';
    runContext = await fileUtils.createRunContext({
      platform: 'x',
      identifier,
      baseOutputDir: config.outputDir,
    });
    engine.eventBus.emitLog(`Created new run context: ${runContext.runId}`);
  }

  const collectedTweets: Tweet[] = [];
  const scrapedIds = new Set<string>();
  let profileInfo: ProfileInfo | null = null;
  let wasmCleanerLogged = false;

  // Session ç®¡ç†ï¼ˆä¸ GraphQL æ¨¡å¼ä¸€è‡´ï¼‰
  const attemptedSessions = new Set<string>();
  const initialSession = engine.getCurrentSession();
  if (initialSession) attemptedSessions.add(initialSession.id);

  // Cancellation checker wrapper
  const shouldStop = () => engine.shouldStop();

  try {
    // æ„å»ºç›®æ ‡ URL
    let targetUrl: string;
    if (mode === 'search' && searchQuery) {
      targetUrl = `https://x.com/search?q=${encodeURIComponent(searchQuery)}&src=typed_query&f=live`;
    } else if (username) {
      targetUrl = `https://x.com/${username}`;
    } else {
      targetUrl = 'https://x.com/home';
    }

    // å¯¼èˆªåˆ°é¡µé¢ï¼ˆå¸¦ session åˆ‡æ¢é‡è¯•é€»è¾‘ï¼‰
    let navigationSuccess = false;
    let navigationAttempts = 0;
    const maxNavigationAttempts = 4; // æœ€å¤šå°è¯•4ä¸ªsession

    while (!navigationSuccess && navigationAttempts < maxNavigationAttempts) {
      if (await shouldStop()) break;
      try {
        engine.performanceMonitor.startPhase('navigation');
        // biome-ignore lint/style/noNonNullAssertion: page ensured
        await waitOrCancel(
          engine.navigationService.navigateToUrl(engine.getPageInstance()!, targetUrl),
          shouldStop
        );
        
        if (await shouldStop()) break;

        const tweetsFound = await waitOrCancel(
          engine.navigationService.waitForTweets(
            // biome-ignore lint/style/noNonNullAssertion: page ensured
            engine.getPageInstance()!,
            {
              timeout: 10000, // å‡å°‘è¶…æ—¶æ—¶é—´
              maxRetries: 1, // åªé‡è¯•1æ¬¡
            }
          ),
          shouldStop
        );

        engine.performanceMonitor.endPhase();
        navigationSuccess = true;

        if (!tweetsFound) {
          engine.eventBus.emitLog(
            'No tweets found for this query/chunk (valid empty state). Skipping extraction.',
            'info',
          );
          // Return early with success and empty tweets
          return {
            success: true,
            tweets: [],
            runContext,
            profile: profileInfo,
            performance: engine.performanceMonitor.getStats(),
          };
        }
        // biome-ignore lint/suspicious/noExplicitAny: error handling
      } catch (navError: any) {
        if (navError.message === 'Job cancelled by user') throw navError;

        engine.performanceMonitor.endPhase();
        navigationAttempts++;
        engine.eventBus.emitLog(
          `Page load failed (attempt ${navigationAttempts}/${maxNavigationAttempts}): ${navError.message}`,
          'warn',
        );

        if (navigationAttempts >= maxNavigationAttempts) {
          throw new Error(`Failed to load page after ${maxNavigationAttempts} attempts`);
        }

        // å°è¯•åˆ‡æ¢ Session
        if (config.enableRotation && navigationAttempts < maxNavigationAttempts) {
          const nextSession = await engine.sessionManager.getNextSession();
          if (nextSession) {
            try {
              // Use restartBrowserWithSession to ensure IP switch during navigation rotation
              await waitOrCancel(engine.restartBrowserWithSession(nextSession), shouldStop);
              engine.eventBus.emitLog(`Rotated to session: ${nextSession.id}`, 'info');

              // å‡å°‘ç­‰å¾…æ—¶é—´ï¼ŒåŠ å¿«åˆ‡æ¢ï¼ˆä»2000mså‡å°‘åˆ°500msï¼‰
              await sleepOrCancel(500, shouldStop);
              // biome-ignore lint/suspicious/noExplicitAny: error handling
            } catch (e: any) {
              if (e.message === 'Job cancelled by user') throw e;
              engine.eventBus.emitLog(`Session rotation failed: ${e.message}`, 'error');
              attemptedSessions.add(nextSession.id);
            }
          } else {
            engine.eventBus.emitLog(`All sessions attempted. Stopping.`, 'error');
            break;
          }
        } else {
          // ä¸´æ—¶é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
          const waitTime = 2000 + Math.random() * 1000;
          await sleepOrCancel(waitTime, shouldStop);
        }
      }
    }

    if (await shouldStop()) {
      throw new Error('Job cancelled by user');
    }

    // æå–èµ„æ–™ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯ç”¨æˆ·é¡µé¢ï¼‰
    if (username && config.collectProfileInfo) {
      if (await shouldStop()) throw new Error('Job cancelled by user');
      const page = engine.getPageInstance();
      if (page) {
        profileInfo = await dataExtractor.extractProfileInfo(page);
      }
    }

    // æ»šåŠ¨å¹¶æå–æ¨æ–‡
    let consecutiveNoNew = 0;
    // é’ˆå¯¹ mixed ç»­è·‘åœºæ™¯ï¼Œä½¿ç”¨æ€»ç›®æ ‡è€Œéæœ¬åœ° remainingLimit æ¥å†³å®šè€å¿ƒé˜ˆå€¼
    const effectiveTarget = totalTarget;
    // å¯¹äºå¤§ç›®æ ‡ï¼ˆ>500æ¡ï¼‰ï¼Œé€‚åº¦å¢åŠ è¿ç»­æ— æ–°æ¨æ–‡çš„å®¹å¿åº¦
    // é™ä½æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œé¿å…è¿‡é•¿æ—¶é—´çš„æ— æ•ˆé‡å¤å°è¯•
    const maxNoNew =
      effectiveTarget > 500
        ? Math.max(constants.MAX_CONSECUTIVE_NO_NEW_TWEETS * 2, 5)
        : constants.MAX_CONSECUTIVE_NO_NEW_TWEETS;
    let consecutiveErrors = 0;

    // è®°å½•æ‰€æœ‰ session éƒ½æ— æ³•åŠ è½½æ–°æ¨æ–‡çš„æ¬¡æ•°
    let sessionsFailedCount = 0;
    const MAX_SESSIONS_FAILED = 2; // å¦‚æœè¿ç»­2ä¸ªsessionéƒ½æ— æ³•åŠ è½½æ–°æ¨æ–‡ï¼Œå¯èƒ½æ˜¯å¹³å°é™åˆ¶

    // Deep Search å˜é‡ (Placeholder for future use or removal if unused)
    // const deepSearchMode = false;
    // const deepSearchScrolls = 0;
    // const MAX_DEEP_SEARCH_SCROLLS = 20;

    engine.performanceMonitor.startPhase('main-loop');

    while (collectedTweets.length < limit && consecutiveNoNew < maxNoNew) {
      if (await shouldStop()) {
        engine.eventBus.emitLog('Manual stop signal received', 'warn');
        break;
      }

      // Extraction Phase
      try {
        engine.performanceMonitor.startPhase('extraction');
        // biome-ignore lint/style/noNonNullAssertion: page existence checked by ensurePage
        let tweetsOnPage = await waitOrCancel(dataExtractor.extractTweetsFromPage(engine.getPageInstance()!), shouldStop);
        engine.performanceMonitor.endPhase();

        // æ£€æŸ¥é¡µé¢æ˜¯å¦æ˜¾ç¤ºé”™è¯¯æˆ–é™åˆ¶ï¼ˆå¦‚ "Something went wrong", "Rate limit" ç­‰ï¼‰
        const pageText = await engine.getPageInstance()?.evaluate(() => document.body.innerText);
        const hasError =
          /rate limit|something went wrong|try again later|suspended|restricted|blocked/i.test(
            pageText || '',
          );

        if (hasError && tweetsOnPage.length === 0) {
          // å°è¯•ä»é”™è¯¯é¡µé¢æ¢å¤ï¼šè‡ªåŠ¨ç‚¹å‡» "Try Again" æŒ‰é’®
          engine.eventBus.emitLog(
            'Error page detected. Attempting to recover by clicking "Try Again" button...',
            'warn',
          );

          // biome-ignore lint/style/noNonNullAssertion: page exists
          const recovered = await dataExtractor.recoverFromErrorPage(engine.getPageInstance()!, 2, shouldStop);

          if (recovered) {
            engine.eventBus.emitLog(
              'Successfully recovered from error page. Re-extracting tweets...',
              'info',
            );
            // é‡æ–°æå–æ¨æ–‡
            await sleepOrCancel(2000, shouldStop); // ç­‰å¾…é¡µé¢åŠ è½½
            // biome-ignore lint/style/noNonNullAssertion: page exists
            tweetsOnPage = await waitOrCancel(dataExtractor.extractTweetsFromPage(engine.getPageInstance()!), shouldStop);
            if (tweetsOnPage.length > 0) {
              engine.eventBus.emitLog(
                `Recovery successful: found ${tweetsOnPage.length} tweets after retry.`,
                'info',
              );
            } else {
              // æ¢å¤åä»ç„¶æ²¡æœ‰æ¨æ–‡ï¼Œå¯èƒ½æ˜¯çœŸçš„æ²¡æœ‰å†…å®¹
              engine.eventBus.emitLog(
                'Recovery successful but no tweets found. This may be normal.',
                'info',
              );
            }
          } else {
            // æ¢å¤å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            throw ScraperErrors.apiRequestFailed(
              'Page shows error or rate limit message and recovery failed',
              undefined,
              { url: 'https://x.com' },
            );
          }
        }

        const cleaned = await cleanTweetsFast([], tweetsOnPage, { limit });
        if (cleaned.usedWasm && !wasmCleanerLogged) {
          engine.eventBus.emitLog('Using Rust/WASM tweet cleaner for normalization/dedup.', 'info');
          wasmCleanerLogged = true;
        }

        let addedCount = 0;
        for (const tweet of cleaned.tweets) {
          if (collectedTweets.length >= limit) break;
          if (scrapedIds.has(tweet.id)) continue;

          // Check stop conditions
          if (config.stopAtTweetId && tweet.id === config.stopAtTweetId) {
            engine.eventBus.emitLog(`Reached stop tweet ID: ${tweet.id}`);
            consecutiveNoNew = maxNoNew; // Stop loop
            break;
          }
          if (config.sinceTimestamp && tweet.time) {
            const tweetTime = new Date(tweet.time).getTime();
            if (tweetTime < config.sinceTimestamp) {
              engine.eventBus.emitLog(`Reached time limit: ${tweet.time}`);
              consecutiveNoNew = maxNoNew; // Stop loop
              break;
            }
          }

          collectedTweets.push(tweet);
          scrapedIds.add(tweet.id);
          addedCount++;
        }

        engine.eventBus.emitLog(
          `Extracted ${cleaned.tweets.length} cleaned tweets (raw ${tweetsOnPage.length}), added ${addedCount} new. Total: ${collectedTweets.length}`,
        );

        // Update performance monitor
        engine.performanceMonitor.recordTweets(collectedTweets.length);
        engine.emitPerformanceUpdate();

        // Update progress
        const currentProgress = progressBase + collectedTweets.length;
        engine.eventBus.emitProgress({
          current: Math.min(currentProgress, totalTarget), // ä¸è¶…è¿‡ç›®æ ‡
          target: totalTarget,
          action: 'scraping (DOM)',
        });

        // å¦‚æœè¾¾åˆ°ç›®æ ‡ï¼Œåº”è¯¥åœæ­¢
        if (currentProgress >= totalTarget) {
          engine.eventBus.emitLog(
            `âœ… Target of ${totalTarget} reached. Stopping extraction.`,
            'info',
          );
          break;
        }

        // æ£€æŸ¥åœæ­¢ä¿¡å·ï¼ˆå¯èƒ½åŒ…å«å…¨å±€é™åˆ¶æ£€æŸ¥ï¼‰
        if (await shouldStop()) {
          engine.eventBus.emitLog(
            'Stop signal received (may be global limit reached). Stopping extraction.',
            'info',
          );
          break;
        }

        // é‡ç½®é”™è¯¯è®¡æ•°ï¼ˆæˆåŠŸæå–ï¼‰
        consecutiveErrors = 0;

        if (addedCount === 0) {
          consecutiveNoNew++;
          engine.eventBus.emitLog(
            `No new tweets found (consecutive: ${consecutiveNoNew}/${maxNoNew}). Continuing to scroll...`,
            'debug',
          );

          // æ™ºèƒ½åˆ¤æ–­ï¼šè¯†åˆ«è¾¹ç•Œé—®é¢˜ vs sessioné—®é¢˜
          // å…³é”®æ”¹è¿›ï¼šåœ¨ Date Chunking æ¨¡å¼ä¸‹ï¼Œæ›´æ¿€è¿›åœ°è¯†åˆ«è¾¹ç•Œ
          const totalCount = collectedTweets.length + progressBase;
          // ğŸ”‘ ä¿®å¤ï¼šé€šè¿‡ mode === 'search' åˆ¤æ–­æ˜¯å¦æ˜¯ chunk æ¨¡å¼
          // ä¹‹å‰ç”¨ progressBase > 0 åˆ¤æ–­ï¼Œä½†ç¬¬ä¸€ä¸ª chunk çš„ progressBase = 0ï¼
          const isChunkMode = mode === 'search';
          const chunkTweetCount = collectedTweets.length; // è¿™ä¸ªchunkæ”¶é›†çš„æ¨æ–‡æ•°

          // æ—¥æœŸåˆ†å—æ¨¡å¼ä¸‹çš„è¾¹ç•Œåˆ¤æ–­ï¼ˆè¶…çº§æ¿€è¿›ç­–ç•¥ï¼‰:
          // ç”¨æˆ·çš„ç—›ç‚¹ï¼šæ˜æ˜æ˜¯è¯¥æ—¥æœŸèŒƒå›´å†…æ²¡æ¨æ–‡äº†ï¼Œè¿˜åœ¨åˆ‡å·å°è¯•
          // ä¿®æ­£ï¼šåªè¦æ”¶é›†åˆ°äº†å°‘é‡æ¨æ–‡ï¼ˆ>5æ¡ï¼‰ä¸”è¿ç»­2æ¬¡æ²¡æ–°æ¨æ–‡ï¼Œå°±è®¤ä¸ºæ˜¯è¯¥Chunkç»“æŸ
          // æˆ–è€…ï¼šå³ä½¿æ²¡æ”¶é›†åˆ°æ¨æ–‡ï¼Œè¿ç»­4æ¬¡æ²¡æ–°æ¨æ–‡ä¹Ÿè®¤ä¸ºæ˜¯ç»“æŸï¼ˆç©ºChunkï¼‰
          const isLikelyBoundary =
            isChunkMode &&
            (consecutiveNoNew >= 4 || // è¿ç»­4æ¬¡æ— æ–°ï¼Œç›´æ¥ç»“æŸï¼ˆé’ˆå¯¹ç©ºChunkæˆ–å°‘å†…å®¹Chunkï¼‰
              (chunkTweetCount >= 5 && consecutiveNoNew >= 2)); // åªè¦æœ‰å†…å®¹ï¼Œå¯¹â€œæ— æ–°æ¨æ–‡â€çš„å®¹å¿åº¦æä½

          // å¦‚æœè¯†åˆ«ä¸ºè¾¹ç•Œï¼Œç«‹å³åœæ­¢ï¼Œä¸è¦æµªè´¹æ—¶é—´åˆ‡æ¢session
          if (isLikelyBoundary) {
            engine.eventBus.emitLog(
              `âœ… Chunk boundary reached (${chunkTweetCount} tweets, ${consecutiveNoNew} consecutive no-new). Moving to next chunk.`,
              'info',
            );
            break; // è·³å‡ºå¾ªç¯ï¼Œåœæ­¢è¿™ä¸ªchunk
          }

          // å¦‚æœä¸æ˜¯è¾¹ç•Œï¼Œç»§ç»­åˆ¤æ–­å…¶ä»–æƒ…å†µï¼ˆä»…é chunk æ¨¡å¼ï¼‰
          const isLowCount = !isChunkMode && totalCount < 200;
          const isHighCount = totalCount >= 500;

          // è°ƒæ•´åˆ‡æ¢sessionçš„é˜ˆå€¼
          // å…³é”®ä¿®æ­£ï¼šåœ¨ Search/Chunk æ¨¡å¼ä¸‹ï¼Œç¦ç”¨åŸºäº"è¿ç»­æ— æ–°æ¨æ–‡"çš„ Session è½®æ¢
          // åŸå› ï¼šSearch æ¨¡å¼ä¸‹"æ²¡æ¨æ–‡"é€šå¸¸å°±æ˜¯"æ²¡ç»“æœ"ï¼Œæ¢å·ä¹Ÿä¸€æ ·ã€‚è½®æ¢åªä¼šæµªè´¹æ—¶é—´ã€‚
          // åªæœ‰é‡åˆ°æ˜¾å¼ Error (catchå—) æ—¶æ‰è½®æ¢ã€‚
          let sessionSwitchThreshold: number;
          if (isChunkMode) {
             sessionSwitchThreshold = 999; // å®é™…ä¸Šç¦ç”¨
          } else if (isLowCount) {
            sessionSwitchThreshold = 3; // timelineæ¨¡å¼ï¼šå°½å¿«åˆ‡æ¢
          } else if (isHighCount) {
            sessionSwitchThreshold = Math.min(maxNoNew, 8); // timelineæ¨¡å¼ï¼šæ·±åº¦é™åˆ¶
          } else {
            sessionSwitchThreshold = Math.min(maxNoNew, 6);
          }

          // Check if this is Home Timeline mode (username is null/undefined)
          // In Home Timeline mode, session rotation is meaningless because each account has different feed
          const isHomeTimeline = !username && !searchQuery;

          if (
            consecutiveNoNew >= sessionSwitchThreshold &&
            attemptedSessions.size < 4 &&
            !isLikelyBoundary
          ) {
            // Skip session rotation for Home Timeline mode
            if (isHomeTimeline) {
              engine.eventBus.emitLog(
                `Home Timeline mode detected. Session rotation skipped (each account has different feed). Reached platform limit of ~${collectedTweets.length} tweets.`,
                'warn',
              );
              break; // Stop scraping, we've hit the platform limit
            }

            if (isLowCount) {
              engine.eventBus.emitLog(
                `Low tweet count (${collectedTweets.length}) with ${consecutiveNoNew} consecutive no-new cycles. Likely session issue. Rotating session...`,
                'warn',
              );
            } else {
              engine.eventBus.emitLog(
                `High tweet count (${collectedTweets.length}) with ${consecutiveNoNew} consecutive no-new cycles. May have reached depth limit. Trying session rotation...`,
                'warn',
              );
            }
            const allActiveSessions = await engine.sessionManager.getAllActiveSessions();
            const untriedSessions = allActiveSessions.filter((s) => !attemptedSessions.has(s.id));

            if (untriedSessions.length > 0) {
              const nextSession = untriedSessions[0];
              engine.eventBus.emitLog(`Switching to session: ${nextSession.id}...`, 'info');

              try {
                // Use restartBrowserWithSession to ensure IP switch during scroll rotation
                await waitOrCancel(engine.restartBrowserWithSession(nextSession), shouldStop);
                attemptedSessions.add(nextSession.id);
                consecutiveNoNew = 0; // é‡ç½®è®¡æ•°å™¨ï¼Œç»™æ–°sessionæœºä¼š
                engine.performanceMonitor.recordSessionSwitch();

                // åˆ‡æ¢ session åï¼Œåˆ·æ–°é¡µé¢ä»¥åº”ç”¨æ–° cookies
                engine.eventBus.emitLog(
                  `Switched to session: ${nextSession.id} (${attemptedSessions.size} session(s) tried). Refreshing and performing rapid deep scroll...`,
                  'info',
                );

                // waitForTweets å¤±è´¥æ—¶å¿«é€Ÿé‡è¯•ä¸€æ¬¡ï¼Œå‡å°‘è¶…æ—¶æ—¶é—´
                try {
                  // biome-ignore lint/style/noNonNullAssertion: page exists
                  await waitOrCancel(
                    engine.navigationService.waitForTweets(engine.getPageInstance()!, {
                    timeout: 10000, // Increase from 3s to 10s to prevent flakes
                    maxRetries: 1, // Allow 1 retry
                  }), shouldStop);
                } catch (_navErr) {
                  engine.eventBus.emitLog(
                    `waitForTweets after session switch failed, skipping retry for faster switching...`,
                    'warn',
                  );
                  // ä¸å†é‡è¯•ï¼Œç›´æ¥ç»§ç»­ï¼ŒåŠ å¿«åˆ‡æ¢é€Ÿåº¦
                }

                // Fast scroll to discover new tweets with new session
                const maxScrollAttempts = 10; // ä»20å‡å°‘åˆ°10ï¼ŒåŠ å¿«å¤±è´¥æ£€æµ‹
                const scrollsPerExtraction = 2; // ä»3å‡å°‘åˆ°2ï¼Œæ›´é¢‘ç¹æ£€æŸ¥

                engine.eventBus.emitLog(
                  `Performing rapid deep scroll: ${maxScrollAttempts} scrolls, extracting every ${scrollsPerExtraction} scrolls to check for new tweets...`,
                  'debug',
                );

                let scrollCount = 0;
                let lastExtractionCount = collectedTweets.length;

                while (scrollCount < maxScrollAttempts) {
                  // æ£€æŸ¥ stop ä¿¡å·ï¼ˆåœ¨æ¯æ¬¡å¾ªç¯å¼€å§‹å’Œå…³é”®æ“ä½œå‰ï¼‰
                  if (await shouldStop()) {
                    engine.eventBus.emitLog(
                      'Manual stop signal received during deep scroll. Stopping...',
                      'info',
                    );
                    break;
                  }

                  // å¿«é€Ÿè¿ç»­æ»šåŠ¨ scrollsPerExtraction æ¬¡
                  for (
                    let i = 0;
                    i < scrollsPerExtraction && scrollCount < maxScrollAttempts;
                    i++
                  ) {
                    // åœ¨æ¯æ¬¡æ»šåŠ¨å‰ä¹Ÿæ£€æŸ¥ stop ä¿¡å·
                    if (await shouldStop()) {
                      break;
                    }
                    // ä½¿ç”¨äººæ€§åŒ–æ»šåŠ¨ï¼ˆantiDetection.humanScrollï¼‰
                    // biome-ignore lint/style/noNonNullAssertion: page exists
                    const page = engine.getPageInstance()!;
                    await engine.antiDetection.humanScroll(page, 800, 'down');
                    await engine.antiDetection.betweenActions('fast');
                    scrollCount++;

                    // åœ¨ç­‰å¾…åå†æ¬¡æ£€æŸ¥
                    if (await shouldStop()) {
                      break;
                    }
                  }

                  // åœ¨æå–å‰å†æ¬¡æ£€æŸ¥ stop ä¿¡å·
                  if (await shouldStop()) {
                    engine.eventBus.emitLog(
                      'Manual stop signal received. Stopping extraction...',
                      'info',
                    );
                    break;
                  }

                  // æ¯æ»šåŠ¨ scrollsPerExtraction æ¬¡åï¼Œæå–ä¸€æ¬¡æ¨æ–‡
                  const tweetsOnPage = await waitOrCancel(dataExtractor.extractTweetsFromPage(
                    // biome-ignore lint/style/noNonNullAssertion: page exists
                    engine.getPageInstance()!,
                  ), shouldStop);
                  const cleaned = await cleanTweetsFast([], tweetsOnPage, { limit });
                  if (cleaned.usedWasm && !wasmCleanerLogged) {
                    engine.eventBus.emitLog(
                      'Using Rust/WASM tweet cleaner for normalization/dedup.',
                      'info',
                    );
                    wasmCleanerLogged = true;
                  }

                  const beforeCount = collectedTweets.length;
                  for (const tweet of cleaned.tweets) {
                    if (collectedTweets.length >= limit) break;
                    if (scrapedIds.has(tweet.id)) continue;
                    collectedTweets.push(tweet);
                    scrapedIds.add(tweet.id);
                  }
                  const foundNew = collectedTweets.length > beforeCount;

                  const currentCount = collectedTweets.length;

                  if (foundNew) {
                    // Emit progress update during deep scroll so UI reflects new totals (carry base/target)
                    engine.eventBus.emitProgress({
                      current: progressBase + currentCount,
                      target: totalTarget,
                      action: 'deep-scroll',
                    });

                    // å‘ç°æ–°æ¨æ–‡ï¼Œç»§ç»­æ»šåŠ¨
                    engine.eventBus.emitLog(
                      `Found new tweets during deep scroll! Extracted ${cleaned.tweets.length} cleaned tweets (raw ${tweetsOnPage.length}), added ${currentCount - lastExtractionCount} new. Total: ${currentCount} (scrolled ${scrollCount} times)`,
                      'info',
                    );
                    lastExtractionCount = currentCount;

                    // å¦‚æœå·²ç»è¶…è¿‡ç›®æ ‡æ·±åº¦ï¼Œå¯ä»¥åœæ­¢å¿«é€Ÿæ»šåŠ¨
                    const _tweetCountOnPage = await engine
                      .getPageInstance()
                      ?.evaluate((selector) => {
                        return document.querySelectorAll(selector).length;
                      }, 'article[data-testid="tweet"]');

                    // Continue scrolling to find more tweets
                  } else {
                    // æ²¡æœ‰æ–°æ¨æ–‡ï¼Œæ£€æŸ¥æ˜¯å¦åˆ°è¾¾è¾¹ç•Œ
                    const tweetCountOnPage =
                      (await engine.getPageInstance()?.evaluate((selector) => {
                        return document.querySelectorAll(selector).length;
                      }, 'article[data-testid="tweet"]')) || 0;

                    // æ¯20æ¬¡æ»šåŠ¨æŠ¥å‘Šä¸€æ¬¡
                    if (scrollCount % 20 === 0) {
                      engine.eventBus.emitLog(
                        `Deep scroll progress: ${scrollCount}/${maxScrollAttempts} scrolls, ${tweetCountOnPage} tweets on page, ${currentCount} collected`,
                        'debug',
                      );
                    }

                    // å¦‚æœé¡µé¢ä¸Šæ¨æ–‡æ•°é‡ç¨³å®šåœ¨å¾ˆä½çš„å€¼ï¼ˆ<30æ¡ï¼‰ï¼Œè¯´æ˜å¯èƒ½æ— æ³•åŠ è½½æ›´å¤š
                    if (tweetCountOnPage < 30 && scrollCount >= 10) {
                      engine.eventBus.emitLog(
                        `Tweet count on page is low (${tweetCountOnPage}) after ${scrollCount} scrolls. This session cannot load deeper content. Platform limit likely reached.`,
                        'warn',
                      );
                      break;
                    }
                  }

                  // å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„æ¨æ–‡ï¼Œåœæ­¢
                  if (collectedTweets.length >= limit) {
                    break;
                  }
                }

                // æ£€æŸ¥åˆ·æ–°åæ˜¯å¦æ‰¾åˆ°äº†æ–°æ¨æ–‡
                const tweetsAfterRefresh = collectedTweets.length;
                const foundNewAfterRefresh = tweetsAfterRefresh > lastExtractionCount;

                engine.eventBus.emitLog(
                  `Completed rapid deep scroll: ${scrollCount} scrolls, collected ${tweetsAfterRefresh} tweets total (${foundNewAfterRefresh ? 'found new tweets' : 'no new tweets found'}).`,
                  'info',
                );

                if (!foundNewAfterRefresh) {
                  // åˆ·æ–°åæ»šåŠ¨å¤šæ¬¡ä»ç„¶æ²¡æœ‰æ–°æ¨æ–‡ï¼Œè¯´æ˜è¿™ä¸ª session ä¹Ÿæ— æ³•çªç ´é™åˆ¶
                  sessionsFailedCount++;
                  engine.eventBus.emitLog(
                    `Session ${nextSession.id} also cannot load more tweets after refresh and deep scroll. Failed sessions: ${sessionsFailedCount}/${MAX_SESSIONS_FAILED}`,
                    'warn',
                  );

                  // å¦‚æœè¿ç»­å¤šä¸ª session éƒ½æ— æ³•åŠ è½½æ–°æ¨æ–‡ï¼Œå¾ˆå¯èƒ½æ˜¯å¹³å°é™åˆ¶
                  if (sessionsFailedCount >= MAX_SESSIONS_FAILED) {
                    engine.eventBus.emitLog(
                      `âš ï¸  Platform depth limit reached! After trying ${sessionsFailedCount} sessions, none can load more tweets. Twitter/X appears to have a ~800 tweet limit per timeline access. Stopping to avoid wasting time.`,
                      'warn',
                    );
                    // è®¾ç½®ä¸ºè¾¾åˆ°æœ€å¤§æ— æ–°æ¨æ–‡æ¬¡æ•°ï¼Œè§¦å‘å¾ªç¯é€€å‡º
                    consecutiveNoNew = maxNoNew;
                    break;
                  }

                  // é‡ç½®è®¡æ•°å™¨ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª session
                  consecutiveNoNew = 0;
                } else {
                  // æ‰¾åˆ°äº†æ–°æ¨æ–‡ï¼Œé‡ç½®å¤±è´¥è®¡æ•°å’Œè®¡æ•°å™¨
                  sessionsFailedCount = 0;
                  consecutiveNoNew = 0;
                }

                // ç»§ç»­å¾ªç¯ï¼Œå°è¯•æå–æ–°å†…å®¹
                continue;
                // biome-ignore lint/suspicious/noExplicitAny: error handling
              } catch (e: any) {
                if (e.message === 'Job cancelled by user') throw e;
                engine.eventBus.emitLog(`Session rotation failed: ${e.message}`, 'error');
                attemptedSessions.add(nextSession.id); // æ ‡è®°ä¸ºå·²å°è¯•
              }
            }
          }

          // å¦‚æœè¿ç»­æ²¡æœ‰æ–°æ¨æ–‡ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç»™ Twitter æ›´å¤šæ—¶é—´åŠ è½½å†…å®¹
          // è¿ç»­æ— æ–°æ¨æ–‡è¶Šå¤šï¼Œç­‰å¾…æ—¶é—´è¶Šé•¿
          if (consecutiveNoNew >= 2) {
            // é™ä½ç­‰å¾…æ—¶é•¿ï¼Œå‡å°‘ç©ºè€—
            const baseDelay = consecutiveNoNew >= 8 ? 2500 : consecutiveNoNew >= 5 ? 2000 : 1200;
            const extraDelay = baseDelay + Math.random() * 500;
            engine.eventBus.emitLog(
              `Adding extra delay (${Math.round(extraDelay)}ms) to allow more content to load (consecutive no-new: ${consecutiveNoNew})...`,
              'debug',
            );

            // åœ¨é•¿æ—¶é—´ç­‰å¾…å‰æ£€æŸ¥ stop ä¿¡å·
            if (await shouldStop()) {
              engine.eventBus.emitLog(
                'Manual stop signal received during delay. Stopping...',
                'info',
              );
              break;
            }

            await sleepOrCancel(extraDelay, shouldStop);

            // ç­‰å¾…åå†æ¬¡æ£€æŸ¥
            if (await shouldStop()) {
              engine.eventBus.emitLog(
                'Manual stop signal received after delay. Stopping...',
                'info',
              );
              break;
            }
          }
        } else {
          consecutiveNoNew = 0;
        }

        // æ£€æŸ¥ stop ä¿¡å·
        if (await shouldStop()) {
          engine.eventBus.emitLog('Manual stop signal received.');
          break;
        }

        // æ»šåŠ¨åŠ è½½æ›´å¤šï¼ˆå³ä½¿è¿ç»­æ²¡æœ‰æ–°æ¨æ–‡ä¹Ÿç»§ç»­å°è¯•ï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§æ¬¡æ•°ï¼‰
        if (collectedTweets.length < limit && consecutiveNoNew < maxNoNew) {
          engine.performanceMonitor.startPhase('scroll');
          engine.performanceMonitor.recordScroll();

          // å¦‚æœè¿ç»­æ— æ–°æ¨æ–‡ï¼Œè¿›è¡Œæ›´æ¿€è¿›çš„æ»šåŠ¨ï¼ˆå¤šæ¬¡æ»šåŠ¨ï¼Œæ›´é•¿çš„ç­‰å¾…æ—¶é—´ï¼‰
          // å…³é”®ï¼šä¸è¦è¿‡æ—©æ”¾å¼ƒï¼Œç»§ç»­æ»šåŠ¨æ›´é•¿æ—¶é—´
          let scrollCount = 1;
          let scrollDelay = constants.getScrollDelay();

          if (consecutiveNoNew >= 5) {
            // è¿ç»­æ— æ–°è¾¾åˆ° 5 ç›´æ¥åˆ¤å®šåˆ°é¡¶ï¼Œè·³å‡ºå¾ªç¯
            engine.eventBus.emitLog(
              `Reached ${consecutiveNoNew} consecutive no-new cycles. Treating as depth boundary.`,
              'warn',
            );
            consecutiveNoNew = maxNoNew;
            break;
          } else if (consecutiveNoNew >= 3) {
            // è¿ç»­3-4æ¬¡ï¼šå°å¹…å¤šæ»šï¼Œä½†ä¸æ”¾å¤§ç­‰å¾…
            scrollCount = 2;
            scrollDelay = constants.getScrollDelay() * 1.2;
            engine.eventBus.emitLog(
              `Consecutive no-new-tweets: ${consecutiveNoNew}. Light aggressive scroll (${scrollCount} scrolls, ${Math.round(scrollDelay)}ms delay)...`,
              'debug',
            );
          }

          for (let i = 0; i < scrollCount; i++) {
            // åœ¨æ¯æ¬¡æ»šåŠ¨å‰æ£€æŸ¥ stop ä¿¡å·
            if (await shouldStop()) {
              engine.eventBus.emitLog(
                'Manual stop signal received during scroll. Stopping...',
                'info',
              );
              break;
            }

            await dataExtractor.scrollToBottomSmart(
              // biome-ignore lint/style/noNonNullAssertion: page exists
              engine.getPageInstance()!,
              constants.WAIT_FOR_NEW_TWEETS_TIMEOUT,
              shouldStop
            );

            // æ¯æ¬¡æ»šåŠ¨åç­‰å¾…ï¼Œç»™å†…å®¹åŠ è½½æ—¶é—´
            await sleepOrCancel(scrollDelay, shouldStop);

            // åœ¨ç­‰å¾…åä¹Ÿæ£€æŸ¥ stop ä¿¡å·
            if (await shouldStop()) {
              engine.eventBus.emitLog('Manual stop signal received. Stopping scroll...', 'info');
              break;
            }

            if (i < scrollCount - 1) {
              engine.eventBus.emitLog(
                `Additional scroll ${i + 2}/${scrollCount} to load more content...`,
                'debug',
              );
            }
          }

          engine.performanceMonitor.endPhase();
        }
        // biome-ignore lint/suspicious/noExplicitAny: error handling
      } catch (error: any) {
        if (error.message === 'Job cancelled by user') throw error;
        engine.performanceMonitor.endPhase();
        consecutiveErrors++;
        engine.eventBus.emitLog(
          `Error during extraction: ${error instanceof Error ? error.message : String(error)}`,
          'error',
        );

        // å¤„ç†é”™è¯¯ï¼šå¦‚æœæ˜¯é¡µé¢é”™è¯¯æˆ–è¿ç»­é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢ session
        if (
          error.message.includes('rate limit') ||
          error.message.includes('error') ||
          consecutiveErrors >= 3
        ) {
          engine.performanceMonitor.recordRateLimit();
          engine.eventBus.emitLog(`Page error detected. Attempting session rotation...`, 'warn');

          const allActiveSessions = await engine.sessionManager.getAllActiveSessions();
          const untriedSessions = allActiveSessions.filter((s) => !attemptedSessions.has(s.id));

          if (untriedSessions.length > 0) {
            const nextSession = untriedSessions[0];
            try {
              await engine.applySession(nextSession, {
                refreshFingerprint: false,
                clearExistingCookies: true,
              });
              attemptedSessions.add(nextSession.id);
              consecutiveErrors = 0;
              consecutiveNoNew = 0;
              engine.performanceMonitor.recordSessionSwitch();

              // é‡æ–°å¯¼èˆªåˆ°ç›®æ ‡URL
              engine.performanceMonitor.startPhase('navigation');
              // biome-ignore lint/style/noNonNullAssertion: page exists
              await waitOrCancel(engine.navigationService.navigateToUrl(engine.getPageInstance()!, targetUrl), shouldStop);
              // biome-ignore lint/style/noNonNullAssertion: page exists
              await waitOrCancel(engine.navigationService.waitForTweets(engine.getPageInstance()!, {
                timeout: 8000, // å‡å°‘è¶…æ—¶æ—¶é—´ï¼ŒåŠ å¿«åˆ‡æ¢
                maxRetries: 0, // ä¸é‡è¯•ï¼Œå¿«é€Ÿåˆ‡æ¢
              }), shouldStop);
              engine.performanceMonitor.endPhase();

              engine.eventBus.emitLog(
                `Switched to session: ${nextSession.id} (${attemptedSessions.size} session(s) tried). Retrying...`,
                'info',
              );
              // biome-ignore lint/suspicious/noExplicitAny: error handling
            } catch (e: any) {
              if (e.message === 'Job cancelled by user') throw e;
              engine.eventBus.emitLog(`Session rotation failed: ${e.message}`, 'error');
              attemptedSessions.add(nextSession.id);
            }
          } else {
            engine.eventBus.emitLog(`All sessions attempted. Stopping.`, 'error');
            break;
          }
        } else {
          // ä¸´æ—¶é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
          const waitTime = 2000 + Math.random() * 1000;
          await sleepOrCancel(waitTime, shouldStop);
        }
      }
    }

    // Save Results
    engine.performanceMonitor.startPhase('save-results');
    if (collectedTweets.length > 0) {
      if (saveMarkdown) await markdownUtils.saveTweetsAsMarkdown(collectedTweets, runContext);
      if (exportCsv) await exportUtils.exportToCsv(collectedTweets, runContext);
      if (exportJson) await exportUtils.exportToJson(collectedTweets, runContext);
      const page = engine.getPageInstance();
      if (saveScreenshots && page) {
        await screenshotUtils.takeTimelineScreenshot(page, { runContext, filename: 'final.png' });
      }
    }
    engine.performanceMonitor.endPhase();

    const activeSession = engine.getCurrentSession();
    if (activeSession) {
      engine.sessionManager.markGood(activeSession.id);
    }

    engine.performanceMonitor.stop();
    engine.emitPerformanceUpdate(true);
    engine.eventBus.emitLog(engine.performanceMonitor.getReport());

    return {
      success: true,
      tweets: collectedTweets,
      runContext,
      profile: profileInfo,
      performance: engine.performanceMonitor.getStats(),
    };
    // biome-ignore lint/suspicious/noExplicitAny: error handling
  } catch (error: any) {
    if (error.message === 'Job cancelled by user' || await shouldStop()) {
      // If we are stopping, any protocol/detached error is likely a side effect
      if (
        error.message.includes('detached Frame') ||
        error.message.includes('Target closed') ||
        error.message.includes('Session closed') ||
        error.message.includes('Protocol error')
      ) {
         throw new Error('Job cancelled by user');
      }
      throw error;
    }
    
    engine.performanceMonitor.stop();
    engine.eventBus.emitError(new Error(`DOM scraping failed: ${error.message}`));

    // å°è¯•ä¿å­˜é”™è¯¯å¿«ç…§
    const page = engine.getPageInstance();
    if (page) {
      await engine.errorSnapshotter.capture(page, error, 'timeline-dom');
    }

    return { success: false, tweets: collectedTweets, error: error.message };
  }
}
